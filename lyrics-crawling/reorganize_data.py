#!/usr/bin/env python3
"""
ëª¨ë“  ì¸ë±ìŠ¤ë³„ CSV íŒŒì¼ì„ í•˜ë‚˜ì˜ ìµœì¢… íŒŒì¼ë¡œ ë³‘í•©í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import pandas as pd
import os
from datetime import datetime
import glob

def reorganize_data():
    """indexes ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  CSV íŒŒì¼ì„ ë³‘í•©"""

    print(f"\n{'='*60}")
    print(f"Data Reorganization - {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"{'='*60}\n")

    # indexes ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  CSV íŒŒì¼ ì°¾ê¸°
    index_dir = 'song_lists/indexes'
    csv_files = glob.glob(os.path.join(index_dir, '*.csv'))

    if not csv_files:
        print(f"âŒ No CSV files found in {index_dir}")
        return None

    # ëª¨ë“  CSV íŒŒì¼ ì½ì–´ì„œ ë³‘í•©
    all_dataframes = []
    total_songs = 0

    # ì •ë ¬ëœ ìˆœì„œë¡œ íŒŒì¼ ì²˜ë¦¬
    csv_files.sort()

    for csv_file in csv_files:
        filename = os.path.basename(csv_file)
        index_char = filename.replace('.csv', '')

        try:
            df = pd.read_csv(csv_file, encoding='utf-8')

            # index ì—´ì´ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œí•œ ë¬¸ìë¡œ ì„¤ì •
            if 'index' not in df.columns or df['index'].isna().all():
                df['index'] = index_char

            all_dataframes.append(df)
            count = len(df)
            total_songs += count
            print(f"âœ… Loaded {index_char}: {count:,} songs")

        except Exception as e:
            print(f"âŒ Error loading {filename}: {e}")
            continue

    if not all_dataframes:
        print("âŒ No data could be loaded")
        return None

    # ëª¨ë“  ë°ì´í„°í”„ë ˆì„ ë³‘í•©
    print(f"\nğŸ“Š Merging all data...")
    final_df = pd.concat(all_dataframes, ignore_index=True)

    # ì—´ ìˆœì„œ ì •ë¦¬
    columns = ['index', 'title', 'artist', 'songwriter', 'composer', 'url', 'preview']
    for col in columns:
        if col not in final_df.columns:
            final_df[col] = None
    final_df = final_df[columns]

    # ì¤‘ë³µ ì œê±° (URL ê¸°ì¤€)
    before_dedup = len(final_df)
    final_df = final_df.drop_duplicates(subset=['url'], keep='first')
    after_dedup = len(final_df)

    if before_dedup != after_dedup:
        print(f"âš ï¸  Removed {before_dedup - after_dedup} duplicate entries")

    # ìµœì¢… íŒŒì¼ ì €ì¥
    output_path = 'song_lists/all_songs.csv'
    final_df.to_csv(output_path, index=False, encoding='utf-8')
    print(f"\nğŸ’¾ Saved final data to: {output_path}")

    # í†µê³„ ì •ë³´ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ“ˆ Final Statistics:")
    print(f"{'='*60}")
    print(f"  Total songs: {len(final_df):,}")
    print(f"  Unique artists: {final_df['artist'].nunique():,}")
    print(f"\n  Data distribution by index:")

    # ì¸ë±ìŠ¤ë³„ ë¶„í¬ë¥¼ íˆë¼ê°€ë‚˜ ìˆœì„œë¡œ ì •ë ¬
    index_order = ['ã‚', 'ã„', 'ã†', 'ãˆ', 'ãŠ', 'ã‹', 'ã', 'ã', 'ã‘', 'ã“',
                   'ã•', 'ã—', 'ã™', 'ã›', 'ã', 'ãŸ', 'ã¡', 'ã¤', 'ã¦', 'ã¨',
                   'ãª', 'ã«', 'ã¬', 'ã­', 'ã®', 'ã¯', 'ã²', 'ãµ', 'ã¸', 'ã»',
                   'ã¾', 'ã¿', 'ã‚€', 'ã‚', 'ã‚‚', 'ã‚„', 'ã‚†', 'ã‚ˆ',
                   'ã‚‰', 'ã‚Š', 'ã‚‹', 'ã‚Œ', 'ã‚', 'ã‚', 'ã‚’', 'ã‚“']

    index_counts = final_df['index'].value_counts()

    # ì¡´ì¬í•˜ëŠ” ì¸ë±ìŠ¤ë§Œ ìˆœì„œëŒ€ë¡œ ì¶œë ¥
    for idx in index_order:
        if idx in index_counts.index:
            count = index_counts[idx]
            print(f"    {idx}: {count:,} songs")

    # íˆë¼ê°€ë‚˜ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ì¶”ê°€ë¡œ ì¶œë ¥
    other_indices = [idx for idx in index_counts.index if idx not in index_order]
    if other_indices:
        print(f"\n  Other indices:")
        for idx in sorted(other_indices):
            count = index_counts[idx]
            print(f"    {idx}: {count:,} songs")

    print(f"\nâœ¨ Data reorganization completed successfully!")
    return final_df


if __name__ == '__main__':
    reorganize_data()